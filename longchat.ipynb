{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY1', 'YourAPIKeyIfNotSet')\n",
    "# llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "openai.api_key = \"shale-xKZC4rjZzC7XGl\" \n",
    "openai.api_base = \"https://shale.live/v1\"\n",
    "model = \"longchat-13b-16k\"\n",
    "\n",
    "llm = OpenAI(model_name=model, temperature=0, openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/clzhang/Desktop/can_ali_paper.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Printing the first 285 characters as a preview\n",
    "print (text[:285])\n",
    "\n",
    "num_tokens = llm.get_num_tokens(text)\n",
    "print (f\"There are {num_tokens} tokens in your file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=3000, chunk_overlap=350)\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce')#, verbose=True) #  optional to see what is getting sent to the LLM\n",
    "\n",
    "# Use it. This will run through the 4 documents, summarize the chunks, then get a summary of the summary.\n",
    "output = chain.run(docs)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "import requests\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    model_engine: str\n",
    "    max_tokens: int\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        return self.get_response_of_modelhub(prompt)\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"model_engine\": self.model_engine, \"max_tokens\": self.max_tokens}\n",
    "\n",
    "    def get_response_of_modelhub(self, user_msg, system_msg=\"\"):\n",
    "        model_engine_dict = {\n",
    "            \"baichuan2-13b-chat-chatsft-epo5\": \"k8s-sv0-us1iys-1696926571411\"\n",
    "        }\n",
    "        model_id = model_engine_dict[self.model_engine]\n",
    "\n",
    "        url = 'http://luban-llm.intra.xiaojukeji.com/generate'\n",
    "        headers = {\n",
    "            'X-Luban-LLM-Service-APPId': model_id,\n",
    "            'X-ModelHub-Token': '45GKEKUHEPIOWFF5Y4JVZH26UTF7ZXZMCAIGUIFOPXKK2XSX6QGCJCPGRW5ENZBTOAJW7KGK73FC7GYS6UXXZJWMW3N3F3CE3VLODP3MIQQUQ7JFTUVHROCDH7GK7EIEVBJ5SMZLXNFLNYUHMCBZTD6CQM======',\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "        msg = user_msg\n",
    "        # print('msg:\\n{}'.format(msg))\n",
    "        data = {\n",
    "            'inputs': msg,\n",
    "            'parameters': {\n",
    "                'max_new_tokens': self.max_tokens,\n",
    "                \"temperature\":0.1,\n",
    "                \"top_p\": 0.9,\n",
    "                \"repetition_penalty\": 1.1\n",
    "                }\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        # print('response:\\n {}'.format(response.json()))\n",
    "        # print('response:\\n {}'.format(response.json()['generated_text']))\n",
    "        return response.json()['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20930 ['namedingï¼š@ğŸŒ¸st*é›ªï¼ˆé˜³ï¼‰\\u2005', 'namedingï¼šä½ 51ä¸ªçº¢åŒ…å¤šå°‘é’±', 'wxid_2k71jfnx1xbp22ï¼šæ²¡çœ‹å•Šï¼Œæ²¡å‡ æ¯›', 'namedingï¼š8 å¸®æˆ‘åŠ©åŠ› f:/ å§ï¼Œä¸ŠæŠ–-yinä¸€èµ·å†²å§ï¼ç†å”±ä¹Ÿæ‹‰æ…¢åç©¶ä½†å¯¾', 'namedingï¼šç‚¹äº†åå‡ ä¸ªçº¢åŒ…æ‰ä¸€å—', 'wxid_2xgo1gspcjag22ï¼šæ³¨æ„æ°¢èƒ½æº    åˆ¶æ°¢ï¼Œå‚¨æ°¢', 'zzj457070921ï¼šå…°çŸ³é‡è£…æˆ‘ä¸€ç›´åŸ‹ä¼ç€', 'wxid_2xgo1gspcjag22ï¼šé•‡æ´‹å·²ç»å¯åŠ¨   ä¹”æºä¹Ÿæ¶¨äº†', 'wxid_2xgo1gspcjag22ï¼šæ”¶è·å®‡é‚¦æ–°æ   é¼é™…å¾—', 'wxid_2xgo1gspcjag22ï¼šè¿™ä¸¤ä¸ªèµ°çš„å¾ˆå¼º']\n",
      "namedingï¼š@ğŸŒ¸st*é›ªï¼ˆé˜³ï¼‰â€…\n",
      "namedingï¼šä½ 51ä¸ªçº¢åŒ…å¤šå°‘é’±\n",
      "wxid_2k71jfnx1xbp22ï¼šæ²¡çœ‹å•Šï¼Œæ²¡å‡ æ¯›\n",
      "namedingï¼š8 å¸®æˆ‘åŠ©åŠ› f:/ å§ï¼Œä¸ŠæŠ–-yinä¸€èµ·å†²å§ï¼ç†å”±ä¹Ÿæ‹‰æ…¢åç©¶ä½†å¯¾\n",
      "namedingï¼šç‚¹äº†åå‡ ä¸ªçº¢åŒ…æ‰ä¸€å—\n",
      "wxid_2xgo1gspcjag22ï¼šæ³¨æ„æ°¢èƒ½æº    åˆ¶æ°¢ï¼Œå‚¨æ°¢\n",
      "zzj457070921ï¼šå…°çŸ³é‡è£…æˆ‘ä¸€ç›´åŸ‹ä¼ç€\n",
      "wxid_2xgo1gspcjag22ï¼šé•‡æ´‹å·²ç»å¯åŠ¨   ä¹”æºä¹Ÿæ¶¨äº†\n",
      "wxid_2xgo1gspcjag22ï¼šæ”¶è·å®‡é‚¦æ–°æ   é¼é™…å¾—\n",
      "wxid_2xgo1gspcjag22ï¼šè¿™ä¸¤ä¸ªèµ°çš„å¾ˆå¼º\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "all_chats=[]\n",
    "for line in open('data/wechat/ä»™äººæŒ‡è·¯.json'):\n",
    "    chat = json.loads(line)\n",
    "    msg_id, uid, type, ts, msg = chat['msg_id'], chat['uid'], chat['type'], chat['ts'], chat['msg']\n",
    "    if type == 1:\n",
    "        uid_msg = \"{}ï¼š{}\".format(uid, msg)\n",
    "        all_chats.append(uid_msg)\n",
    "print(len(all_chats), all_chats[:10])\n",
    "\n",
    "[print(c) for c in all_chats[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 155 ('ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„å¯¹è¯èŠå¤©åŠ©æ‰‹ã€‚åŸºäºæ‰€æœ‰å¤šè½®èŠå¤©è®°å½•ï¼Œä½ éœ€è¦é€æ­¥å®Œæˆå¦‚ä¸‹ä»»åŠ¡ï¼Œé¦–å…ˆï¼Œå°†èŠå¤©è®°å½•çš„å†…å®¹å½’çº³å‡º2-5ä¸ªæ ¸å¿ƒè¯é¢˜ï¼ˆè¯é¢˜åç§°è¦ç®€æ´ï¼‰ï¼Œ    å¹¶ç®€æ´çš„æ¦‚æ‹¬å‡ºæ¯ä¸ªäººçš„è§‚ç‚¹æˆ–æ€åº¦ï¼›æœ€åé’ˆå¯¹æ¯ä¸ªè¯é¢˜ç»™å‡ºæ€»ç»“å’Œè¦ç‚¹ã€‚æç¤ºï¼š`<|im_start|>`ä»£è¡¨æ¯æ¡èŠå¤©çš„å¼€å§‹ï¼Œ`<|im_end|>`ä»£è¡¨æ¯æ¡èŠå¤©çš„ç»“æŸã€‚', '<|im_start|>namedingï¼š@ğŸŒ¸st*é›ªï¼ˆé˜³ï¼‰\\u2005<|im_end|>\\n<|im_start|>namedingï¼šä½ 51ä¸ªçº¢åŒ…å¤šå°‘é’±<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22ï¼šæ²¡çœ‹å•Šï¼Œæ²¡å‡ æ¯›<|im_end|>\\n<|im_start|>namedingï¼š8 å¸®æˆ‘åŠ©åŠ› f:/ å§ï¼Œä¸ŠæŠ–-yinä¸€èµ·å†²å§ï¼ç†å”±ä¹Ÿæ‹‰æ…¢åç©¶ä½†å¯¾<|im_end|>\\n<|im_start|>namedingï¼šç‚¹äº†åå‡ ä¸ªçº¢åŒ…æ‰ä¸€å—<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæ³¨æ„æ°¢èƒ½æº    åˆ¶æ°¢ï¼Œå‚¨æ°¢<|im_end|>\\n<|im_start|>zzj457070921ï¼šå…°çŸ³é‡è£…æˆ‘ä¸€ç›´åŸ‹ä¼ç€<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šé•‡æ´‹å·²ç»å¯åŠ¨   ä¹”æºä¹Ÿæ¶¨äº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæ”¶è·å®‡é‚¦æ–°æ   é¼é™…å¾—<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ä¸¤ä¸ªèµ°çš„å¾ˆå¼º<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ç®—ä¸ç®—ç®¡ä¸ä½æ‰‹ï¼Ÿ<|im_end|>\\n<|im_start|>namedingï¼šä¹°çš„å•¥<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šå®‡é‚¦<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@St*æ˜æ˜(æŠ•èµ„æ˜¯äºæŸçš„æºå¤´)\\u2005<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šé¼é™…å¾—<|im_end|>\\n<|im_start|>namedingï¼šåˆæ˜¯æ¬¡æ–°è‚¡<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šå¯¹<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ç§å±¡åˆ›æ–°é«˜çš„ä¸ªè‚¡   æˆ‘è¿˜æ˜¯æ¯”è¾ƒçœ‹å¥½   å’¬ä¸€å£å°±èµ°äº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@St*æ˜æ˜(æŠ•èµ„æ˜¯äºæŸçš„æºå¤´)\\u2005æ”¶ç›˜èƒ½çº¢  å°±æ”¶ä¸€ä¸ªé¢é’±å°±è¡Œäº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¦æ±‚ä¹Ÿä¸é«˜   æ¯å¤©ä¸€ä¸ªç‚¹   åé¢ä¹ŸæŒºä¸é”™<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šé¼é™…å¾—   æ‰“51å…ƒ  éƒ½æ²¡æœ‰æˆäº¤é‡å‡ºæ¥    çœŸä¸çŸ¥é“åé¢ä¼šä¸ä¼šåæ°´<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šå¡å€äº¿   åˆ°äº†109å…ƒ<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šMD   é˜¶æ®µæ–°é«˜äº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šç‚’ä½œ åˆ‡åˆ°é«˜é€è½¬æ¦‚å¿µäº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ä¸ªç¥¨  åŒ—äº¬æŠ„å®¶   ä»–åœ¨å…ƒæ—¦å‡æœŸç›´æ’­æ—¶å€™   è¯´äº†è¿™ä¸ªç¥¨   çº¢åœˆé‚£ä¸ªåœ°æ–¹ä»–èµ„é‡‘æ²¡æ‰“è¿›å»   <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@æ‰€æœ‰äºº\\u2005é¦–åˆ›è¯åˆ¸  åˆä¸€æ¬¡æ”»17.35<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22ï¼š1<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šä¹…å…¶è½¯ä»¶  è·åˆ©äº†<|im_end|>\\n<|im_start|>namedingï¼šå¦ˆçš„<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22ï¼š[æƒŠè®¶]<|im_end|>\\n<|im_start|>namedingï¼š@ğŸŒ¸st*é›ªï¼ˆé˜³ï¼‰\\u2005æ¢å¤äº†ä¹ˆ<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22ï¼šå·®ä¸å¤šäº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šçœŸç‹—<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šåªè¦ä¸€è¿½å°±ç ¸     ä½å¸å§  å¸çš„å“†å“†å—¦å—¦<|im_end|>\\n<|im_start|>namedingï¼š@èŠéº»èŠ±å„¿\\u2005<|im_end|>\\n<|im_start|>namedingï¼šè¿™ä»–å¦ˆçš„<|im_end|>\\n<|im_start|>namedingï¼šæ‰“æ¿å°±è¢«æ ¸å¼¹<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæˆ‘æ—©ç›˜ä¹°çš„ç¥¨  ä¹Ÿæ˜¯é‚£ä¸ªç†Šæ ·<|im_end|>\\n<|im_start|>namedingï¼šæˆ‘çœ‹ä¹Ÿæ²¡ä»€ä¹ˆå¥—ç‰¢ç›˜å•Š<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè·åˆ©ç›˜å¤šäº†   é¼é™…å¾—å°±æ˜¯è¿™æ ·çš„    <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿˜æœ‰å°±æ˜¯æ¿å—è½®åŠ¨å¤ªä»–å¦ˆå¿«äº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šä½ ä¸æ‰“æå‰é‡     å¾ˆå®¹æ˜“æ ¸æ‰<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šä¸åƒåšçº³å½±ä¸š   æˆ‘è¿˜èƒ½T  <|im_end|>\\n<|im_start|>namedingï¼šæˆ‘è¿˜åšå®ˆè´µç»³<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™è·Ÿçº¿çš„æœ€ä½ä»·å°±æ˜¯12.23å…ƒ   è¿™ä¸€æ®µæ—¶é—´  å®ƒç¢°äº†å¥½å‡ æ¬¡<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@St*æ˜æ˜(æŠ•èµ„æ˜¯äºæŸçš„æºå¤´)\\u2005è´µç»³è‚¡ä»½  èˆªæ¯ç”¨é’¢ç´¢   è¿˜æ˜¯å¯ä»¥çš„<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šä½ åœ¨æ„æ·«æ˜¯ä¸æ˜¯ä¹ é…’å€Ÿå£³<|im_end|>\\n<|im_start|>namedingï¼šæ˜¯çš„<|im_end|>\\n<|im_start|>namedingï¼šå“ˆå“ˆå“ˆ<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæˆ‘åœ¨æ„æ·«   æµæµªåœ°çƒ2<|im_end|>\\n<|im_start|>namedingï¼šä½ çœ‹ç¾ä¸½äº‘èµ°åŠ¿<|im_end|>\\n<|im_start|>namedingï¼šå’Œæ˜“åæ˜¯ä¸æ˜¯ä¸€æ ·<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šå½±è§†ä¼ åª’æ¿å—æ²¡æ•´ä½“ä¸Šèµ°å¼º    ä¸çŸ¥é“åšçº³æ˜¯ä¸æ˜¯ä¸æ¶¨çš„ä¸€æ ¹æ¶¨åœ<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22ï¼šå¤§ç›˜è¦å›è°ƒï¼Œ5å¤©çº¿å¤ªè¿œï¼Œå¿«å‡ä»“<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22ï¼šå¤§ç›˜å…ˆåˆ°5å¤©çº¿ï¼Œæ’‘ä¸ä½åˆ°20çº¿<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22ï¼š300ä¹Ÿä¸è¡Œäº†ï¼Œä»Šå¤©æ—©ä¸Šæœ‰å¼€ä»“çš„å—<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22ï¼šä¼—ä¸šè¾¾ä¸‰è¿ï¼ŒåŠ¨åŠ›æºæ­»è‚¡ï¼Œç‰¹ä¹ˆçš„ï¼Œé€‰é”™å®³æ­»äºº<|im_end|>\\n<|im_start|>namedingï¼šå¤§ç›˜è¿™ä¹ˆæ¶¨çš„é£èµ·ï¼Œè¿æ¿çš„éƒ½æ²¡<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@Aç‹ç‰Œåº·å¥\\u2005æœ‰  å·²ç»è¢«å¹²ä¸‹å»4ä¸ªç‚¹äº†<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22ï¼šæŠ—ä½å•Š<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22ï¼šæ˜å¤©çœ‹æƒ…å†µä¸å¯¹èµ¶ç´§è·‘ï¼Œå¤§ç›˜è¦å›è°ƒ<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22ï¼šåˆ«äººè´ªå©ªæ—¶è¦ä¿æŒè­¦æƒ•<|im_end|>\\n<|im_start|>wxid_ew911lj4llo731ï¼šè¿™ä¸ªå›¾å½¢å’‹æ ·<|im_end|>\\n<|im_start|>wxid_ew911lj4llo731ï¼šæœ‰æ„æ€å§<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæ‹‰èµ·æ¥<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š[æµæ³ª]<|im_end|>\\n<|im_start|>namedingï¼šæ—©ç›˜ä¹°çš„ä¹ˆ<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š9ç‚¹25åˆ†æ”¶è´§   æ”¶ç›˜ä¸€ä¸ªäºä¸€ä¸ªèµš<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š5:5<|im_end|>\\n<|im_start|>namedingï¼šæŒºå¥½<|im_end|>\\n<|im_start|>namedingï¼šæˆ‘ä»Šå¤©åªä¹°äº†ä¸€ä¸ª <|im_end|>\\n<|im_start|>namedingï¼šé«˜å¤„ä¸èƒœå¯’<|im_end|>\\n<|im_start|>namedingï¼šè¿˜æ˜¯è´µç»³å¥½<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šåˆ¸å•†å¾ˆç‹—çš„<|im_end|>\\n<|im_start|>namedingï¼šè¿™ä¸ªæ®è¯´æ˜¯æˆ¿åœ°äº§<|im_end|>\\n<|im_start|>namedingï¼šæˆ‘ä»¬å¥½å‡ ä¸ªåŒäº‹å»é‚£ä¸Šç­äº†<|im_end|>\\n<|im_start|>zzj457070921ï¼šå°¾ç›˜è¿›äº†åŒ»è¯<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæ¿å—å›åˆ°  ä¸Šå‘¨äºŒçš„æ¿å—ä¸Šå»äº†   <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šç™½é…’ä¸æ•°å­—ç¡®æƒ ä¿¡åˆ›<|im_end|>\\n<|im_start|>wxid_ew911lj4llo731ï¼šæŒ‡æ•°6è¿é˜³  è¿æ¿è·Œæˆé¬¼<|im_end|>\\n', '')\n"
     ]
    }
   ],
   "source": [
    "def _format_msg(system_msg, user_msg, model_engine=\"Baichuan2-13b-chat\"):\n",
    "    if model_engine == \"Baichuan2-13b-chat\":\n",
    "        msg = \"<reserved_106>{}èŠå¤©è®°å½•å‡åœ¨```å†…ã€‚```{}```<reserved_107>\".format(system_msg, user_msg)\n",
    "    elif model_engine == \"Baichuan-13B-Chat\":\n",
    "        msg = \"<reserved_102>{}èŠå¤©è®°å½•å‡åœ¨```å†…ã€‚```{}```<reserved_103>\".format(system_msg, user_msg)\n",
    "    elif model_engine == \"chatglm2-6b\":\n",
    "        msg = \"[Round 1]\\n\\né—®ï¼š{}èŠå¤©è®°å½•å‡åœ¨```å†…ã€‚```{}```\\n\\nç­”ï¼š\".format(system_msg, user_msg)\n",
    "    elif model_engine == \"Llama-2-13b-chat-hf\":\n",
    "        msg = \"<<SYS>>\\n{}\\n<</SYS>>\\n\\n[INST]{}[/INST]\".format(system_msg, user_msg)\n",
    "    else:\n",
    "        msg = \"{}èŠå¤©è®°å½•å‡åœ¨```å†…ã€‚```{}```\".format(system_msg, user_msg)\n",
    "    return msg\n",
    "\n",
    "system_msg = '''ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„å¯¹è¯èŠå¤©åŠ©æ‰‹ã€‚åŸºäºæ‰€æœ‰å¤šè½®èŠå¤©è®°å½•ï¼Œä½ éœ€è¦é€æ­¥å®Œæˆå¦‚ä¸‹ä»»åŠ¡ï¼Œé¦–å…ˆï¼Œå°†èŠå¤©è®°å½•çš„å†…å®¹å½’çº³å‡º2-5ä¸ªæ ¸å¿ƒè¯é¢˜ï¼ˆè¯é¢˜åç§°è¦ç®€æ´ï¼‰ï¼Œ\\\n",
    "    å¹¶ç®€æ´çš„æ¦‚æ‹¬å‡ºæ¯ä¸ªäººçš„è§‚ç‚¹æˆ–æ€åº¦ï¼›æœ€åé’ˆå¯¹æ¯ä¸ªè¯é¢˜ç»™å‡ºæ€»ç»“å’Œè¦ç‚¹ã€‚æç¤ºï¼š`<|im_start|>`ä»£è¡¨æ¯æ¡èŠå¤©çš„å¼€å§‹ï¼Œ`<|im_end|>\\n`ä»£è¡¨æ¯æ¡èŠå¤©çš„ç»“æŸã€‚'''\n",
    "user_msgs=[]\n",
    "chat_group_len=80\n",
    "chat_group_num=len(all_chats)//chat_group_len + 1\n",
    "for i in range(chat_group_num):\n",
    "    chat_group = all_chats[i*chat_group_len:(i+1)*chat_group_len]\n",
    "    # random.shuffle(chat_group)\n",
    "    user_msg=\"\".join([\"<|im_start|>{}<|im_end|>\\n\".format(chat) for chat in chat_group])\n",
    "    user_msgs.append((system_msg, user_msg, \"\"))  # (instruction, input, output)\n",
    "    # user_msgs.append((_format_msg(system_msg, user_msg), \"\", \"\"))  # (instruction, input, output)\n",
    "print(len(user_msgs), len(user_msgs[0][0]), user_msgs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def get_response_of_long_chat_summary(system_msg, user_msg, model_engine=\"baichuan2-13b-chat-chatsft-epo5\", max_tokens=1000, chunk_size=1500, chunk_overlap=200):\n",
    "    llm = CustomLLM(model_engine=model_engine, max_tokens=max_tokens)\n",
    "\n",
    "    # åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨\n",
    "    # splitter = RecursiveCharacterTextSplitter(separators=[\"<|im_end|>\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "    def long_chat_summary(llm, chat_log):\n",
    "        # ä½¿ç”¨æ–‡æœ¬åˆ†å‰²å™¨å°†èŠå¤©è®°å½•åˆ†å‰²æˆå¤šä¸ªå—\n",
    "        docs = splitter.create_documents([chat_log])\n",
    "        print(len(docs[0].page_content), docs[0])\n",
    "\n",
    "        map_prompt = PromptTemplate(template=_format_msg(system_msg, \"{text}\"), input_variables=[\"text\"])\n",
    "        combine_prompt = PromptTemplate(template=\"{text}\", input_variables=[\"text\"])\n",
    "        chain = load_summarize_chain(llm=llm, chain_type='map_reduce', map_prompt=map_prompt, verbose=True)#, combine_prompt=combine_prompt) #\n",
    "        output = chain.run(docs)\n",
    "        return output\n",
    "\n",
    "    # æµ‹è¯•ç”¨ä¾‹\n",
    "    # user_msg = ('è¿™æ˜¯ä¸€æ®µéå¸¸é•¿çš„èŠå¤©è®°å½•ï¼Œéœ€è¦è¢«åˆ†å‰²æˆå¤šä¸ªå—è¿›è¡Œæ‘˜è¦.' * 5 + '<|im_end|>\\n') *5\n",
    "    summaries = long_chat_summary(llm, user_msg)\n",
    "    return summaries\n",
    "\n",
    "# get_response_of_long_chat_summary(system_msg,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473 page_content='<|im_start|>namedingï¼š@ğŸŒ¸st*é›ªï¼ˆé˜³ï¼‰\\u2005<|im_end|>\\n<|im_start|>namedingï¼šä½ 51ä¸ªçº¢åŒ…å¤šå°‘é’±<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22ï¼šæ²¡çœ‹å•Šï¼Œæ²¡å‡ æ¯›<|im_end|>\\n<|im_start|>namedingï¼š8 å¸®æˆ‘åŠ©åŠ› f:/ å§ï¼Œä¸ŠæŠ–-yinä¸€èµ·å†²å§ï¼ç†å”±ä¹Ÿæ‹‰æ…¢åç©¶ä½†å¯¾<|im_end|>\\n<|im_start|>namedingï¼šç‚¹äº†åå‡ ä¸ªçº¢åŒ…æ‰ä¸€å—<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæ³¨æ„æ°¢èƒ½æº    åˆ¶æ°¢ï¼Œå‚¨æ°¢<|im_end|>\\n<|im_start|>zzj457070921ï¼šå…°çŸ³é‡è£…æˆ‘ä¸€ç›´åŸ‹ä¼ç€<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šé•‡æ´‹å·²ç»å¯åŠ¨   ä¹”æºä¹Ÿæ¶¨äº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šæ”¶è·å®‡é‚¦æ–°æ   é¼é™…å¾—<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ä¸¤ä¸ªèµ°çš„å¾ˆå¼º<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ç®—ä¸ç®—ç®¡ä¸ä½æ‰‹ï¼Ÿ<|im_end|>\\n<|im_start|>namedingï¼šä¹°çš„å•¥<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šå®‡é‚¦<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@St*æ˜æ˜(æŠ•èµ„æ˜¯äºæŸçš„æºå¤´)\\u2005<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šé¼é™…å¾—<|im_end|>\\n<|im_start|>namedingï¼šåˆæ˜¯æ¬¡æ–°è‚¡<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šå¯¹<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ç§å±¡åˆ›æ–°é«˜çš„ä¸ªè‚¡   æˆ‘è¿˜æ˜¯æ¯”è¾ƒçœ‹å¥½   å’¬ä¸€å£å°±èµ°äº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@St*æ˜æ˜(æŠ•èµ„æ˜¯äºæŸçš„æºå¤´)\\u2005æ”¶ç›˜èƒ½çº¢  å°±æ”¶ä¸€ä¸ªé¢é’±å°±è¡Œäº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¦æ±‚ä¹Ÿä¸é«˜   æ¯å¤©ä¸€ä¸ªç‚¹   åé¢ä¹ŸæŒºä¸é”™<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šé¼é™…å¾—   æ‰“51å…ƒ  éƒ½æ²¡æœ‰æˆäº¤é‡å‡ºæ¥    çœŸä¸çŸ¥é“åé¢ä¼šä¸ä¼šåæ°´<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šå¡å€äº¿   åˆ°äº†109å…ƒ<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šMD   é˜¶æ®µæ–°é«˜äº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šç‚’ä½œ åˆ‡åˆ°é«˜é€è½¬æ¦‚å¿µäº†<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼šè¿™ä¸ªç¥¨  åŒ—äº¬æŠ„å®¶   ä»–åœ¨å…ƒæ—¦å‡æœŸç›´æ’­æ—¶å€™   è¯´äº†è¿™ä¸ªç¥¨   çº¢åœˆé‚£ä¸ªåœ°æ–¹ä»–èµ„é‡‘æ²¡æ‰“è¿›å»   <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22ï¼š@æ‰€æœ‰äºº\\u2005é¦–åˆ›è¯åˆ¸  åˆä¸€æ¬¡æ”»17.35<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22ï¼š1<|im_end|>' metadata={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1926 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2148 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# gpt-35-turbo\n",
      "===========================================\n",
      "\n",
      "\n",
      "# baichuan2-13b-chat-chatsft-epo5\n",
      "===========================================\n",
      "è¯é¢˜1ï¼šå¾®ä¿¡çº¢åŒ…é‡‘é¢\n",
      "- namedingçš„è§‚ç‚¹ï¼šè§‰å¾—èŠ±8å—é’±ä¹°51ä¸ªçº¢åŒ…å¾ˆä¸åˆ’ç®—ã€‚\n",
      "- wxid_2k71jfnx1xbp22çš„è§‚ç‚¹ï¼šå¯¹å¾®ä¿¡çº¢åŒ…çš„é‡‘é¢ä¸æ„Ÿå…´è¶£ï¼Œè®¤ä¸ºæ²¡æœ‰å‡ æ¯›é’±ã€‚\n",
      "\n",
      "è¯é¢˜2ï¼šè‚¡ç¥¨æŠ•èµ„ç­–ç•¥\n",
      "- wxid_2xgo1gspcjag22çš„è§‚ç‚¹ï¼šå…³æ³¨æ°¢èƒ½æºã€åˆ¶æ°¢ã€å‚¨æ°¢ç­‰æ¦‚å¿µè‚¡ï¼Œè®¤ä¸ºé•‡æ´‹å’Œä¹”æºèµ°åŠ¿å¼ºåŠ²ã€‚\n",
      "- zzj457070921çš„è§‚ç‚¹ï¼šæ½œä¼åœ¨å…°çŸ³é‡è£…è¿™åªè‚¡ç¥¨ä¸­ï¼Œè®¤ä¸ºè¯¥è‚¡æœ‰æœ›ä¸Šæ¶¨ã€‚\n",
      "\n",
      "è¯é¢˜3ï¼šæ–°è‚¡äº¤æ˜“ç­–ç•¥\n",
      "- wxid_2xgo1gspcjag22çš„è§‚ç‚¹ï¼šå¯¹æ–°è‚¡é¼é™…å¾—å’Œå®‡é‚¦æ–°ææŒä¹è§‚æ€åº¦ï¼Œè®¤ä¸ºå®ƒä»¬èµ°åŠ¿å¼ºåŠ²ã€‚\n",
      "- namedingçš„è§‚ç‚¹ï¼šè®¤åŒé¼é™…å¾—çš„å¼ºåŠ¿è¡¨ç°ï¼Œä½†å¯¹å®‡é‚¦æ–°ææŒæœ‰æ€€ç–‘æ€åº¦ã€‚\n",
      "\n",
      "æ€»ç»“å’Œè¦ç‚¹ï¼š\n",
      "- å¾®ä¿¡çº¢åŒ…é‡‘é¢ï¼šnamedingè§‰å¾—èŠ±8å—é’±ä¹°51ä¸ªçº¢åŒ…å¾ˆä¸åˆ’ç®—ï¼Œè€Œwxid_2k71jfnx1xbp22å¯¹å¾®ä¿¡çº¢åŒ…çš„é‡‘é¢ä¸æ„Ÿå…´è¶£ã€‚\n",
      "- è‚¡ç¥¨æŠ•èµ„ç­–ç•¥ï¼šwxid_2xgo1gspcjag22å…³æ³¨æ°¢èƒ½æºã€åˆ¶æ°¢ã€å‚¨æ°¢ç­‰æ¦‚å¿µè‚¡ï¼Œè®¤ä¸ºé•‡æ´‹å’Œä¹”æºèµ°åŠ¿å¼ºåŠ²ï¼Œè€Œzzj457070921æ½œä¼åœ¨å…°çŸ³é‡è£…è¿™åªè‚¡ç¥¨ä¸­ã€‚\n",
      "- æ–°è‚¡äº¤æ˜“ç­–ç•¥ï¼šwxid_2xgo1gspcjag22å¯¹æ–°è‚¡é¼é™…å¾—å’Œå®‡é‚¦æ–°ææŒä¹è§‚æ€åº¦ï¼Œè®¤ä¸ºå®ƒä»¬èµ°åŠ¿å¼ºåŠ²ï¼Œè€Œnamedingå¯¹å®‡é‚¦æ–°ææŒæœ‰æ€€ç–‘æ€åº¦ã€‚\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_engines=[\"baichuan2-13b-chat-chatsft-epo5\"]\n",
    "\n",
    "resps_model = []\n",
    "for inst,input,gpt_output in user_msgs[:1]:\n",
    "    resps=[inst,gpt_output]\n",
    "    for model in model_engines:\n",
    "        try:\n",
    "            # response = get_response_of_modelhub(inst, system_msg=input, model_engine=model, max_tokens=1000)\n",
    "            response = get_response_of_long_chat_summary(inst, input, model_engine=model, max_tokens=1000)\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"{e}\")\n",
    "            # time.sleep(3)\n",
    "            continue\n",
    "        # except Exception as e:\n",
    "        #     print(f\"æ•è·åˆ°å¼‚å¸¸ï¼š{e}\")\n",
    "        #     continue\n",
    "        resps.append(response)\n",
    "        print(\"\\n# {}\\n===========================================\".format(\"gpt-35-turbo\"))\n",
    "        print(gpt_output)\n",
    "        print(\"\\n# {}\\n===========================================\".format(model))\n",
    "        # print(response['generated_text'])\n",
    "        print(response)\n",
    "        print('\\n\\n')\n",
    "    resps_model.append(resps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
