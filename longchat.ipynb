{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY1', 'YourAPIKeyIfNotSet')\n",
    "# llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "openai.api_key = \"shale-xKZC4rjZzC7XGl\" \n",
    "openai.api_base = \"https://shale.live/v1\"\n",
    "model = \"longchat-13b-16k\"\n",
    "\n",
    "llm = OpenAI(model_name=model, temperature=0, openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/clzhang/Desktop/can_ali_paper.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Printing the first 285 characters as a preview\n",
    "print (text[:285])\n",
    "\n",
    "num_tokens = llm.get_num_tokens(text)\n",
    "print (f\"There are {num_tokens} tokens in your file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=3000, chunk_overlap=350)\n",
    "docs = text_splitter.create_documents([text])\n",
    "\n",
    "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm=llm, chain_type='map_reduce')#, verbose=True) #  optional to see what is getting sent to the LLM\n",
    "\n",
    "# Use it. This will run through the 4 documents, summarize the chunks, then get a summary of the summary.\n",
    "output = chain.run(docs)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "import requests\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    model_engine: str\n",
    "    max_tokens: int\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        return self.get_response_of_modelhub(prompt)\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {\"model_engine\": self.model_engine, \"max_tokens\": self.max_tokens}\n",
    "\n",
    "    def get_response_of_modelhub(self, user_msg, system_msg=\"\"):\n",
    "        model_engine_dict = {\n",
    "            \"baichuan2-13b-chat-chatsft-epo5\": \"k8s-sv0-us1iys-1696926571411\"\n",
    "        }\n",
    "        model_id = model_engine_dict[self.model_engine]\n",
    "\n",
    "        url = 'xxx'\n",
    "        headers = {\n",
    "            'X-LLM-Service-APPId': model_id,\n",
    "            'X--Token': 'xxx',\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "\n",
    "        msg = user_msg\n",
    "        # print('msg:\\n{}'.format(msg))\n",
    "        data = {\n",
    "            'inputs': msg,\n",
    "            'parameters': {\n",
    "                'max_new_tokens': self.max_tokens,\n",
    "                \"temperature\":0.1,\n",
    "                \"top_p\": 0.9,\n",
    "                \"repetition_penalty\": 1.1\n",
    "                }\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        # print('response:\\n {}'.format(response.json()))\n",
    "        # print('response:\\n {}'.format(response.json()['generated_text']))\n",
    "        return response.json()['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20930 ['nameding：@🌸st*雪（阳）\\u2005', 'nameding：你51个红包多少钱', 'wxid_2k71jfnx1xbp22：没看啊，没几毛', 'nameding：8 帮我助力 f:/ 吧，上抖-yin一起冲吧！理唱也拉慢名究但対', 'nameding：点了十几个红包才一块', 'wxid_2xgo1gspcjag22：注意氢能源    制氢，储氢', 'zzj457070921：兰石重装我一直埋伏着', 'wxid_2xgo1gspcjag22：镇洋已经启动   乔源也涨了', 'wxid_2xgo1gspcjag22：收获宇邦新材   鼎际得', 'wxid_2xgo1gspcjag22：这两个走的很强']\n",
      "nameding：@🌸st*雪（阳） \n",
      "nameding：你51个红包多少钱\n",
      "wxid_2k71jfnx1xbp22：没看啊，没几毛\n",
      "nameding：8 帮我助力 f:/ 吧，上抖-yin一起冲吧！理唱也拉慢名究但対\n",
      "nameding：点了十几个红包才一块\n",
      "wxid_2xgo1gspcjag22：注意氢能源    制氢，储氢\n",
      "zzj457070921：兰石重装我一直埋伏着\n",
      "wxid_2xgo1gspcjag22：镇洋已经启动   乔源也涨了\n",
      "wxid_2xgo1gspcjag22：收获宇邦新材   鼎际得\n",
      "wxid_2xgo1gspcjag22：这两个走的很强\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "all_chats=[]\n",
    "for line in open('data/wechat/仙人指路.json'):\n",
    "    chat = json.loads(line)\n",
    "    msg_id, uid, type, ts, msg = chat['msg_id'], chat['uid'], chat['type'], chat['ts'], chat['msg']\n",
    "    if type == 1:\n",
    "        uid_msg = \"{}：{}\".format(uid, msg)\n",
    "        all_chats.append(uid_msg)\n",
    "print(len(all_chats), all_chats[:10])\n",
    "\n",
    "[print(c) for c in all_chats[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 155 ('你是一个优秀的对话聊天助手。基于所有多轮聊天记录，你需要逐步完成如下任务，首先，将聊天记录的内容归纳出2-5个核心话题（话题名称要简洁），    并简洁的概括出每个人的观点或态度；最后针对每个话题给出总结和要点。提示：`<|im_start|>`代表每条聊天的开始，`<|im_end|>`代表每条聊天的结束。', '<|im_start|>nameding：@🌸st*雪（阳）\\u2005<|im_end|>\\n<|im_start|>nameding：你51个红包多少钱<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22：没看啊，没几毛<|im_end|>\\n<|im_start|>nameding：8 帮我助力 f:/ 吧，上抖-yin一起冲吧！理唱也拉慢名究但対<|im_end|>\\n<|im_start|>nameding：点了十几个红包才一块<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：注意氢能源    制氢，储氢<|im_end|>\\n<|im_start|>zzj457070921：兰石重装我一直埋伏着<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：镇洋已经启动   乔源也涨了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：收获宇邦新材   鼎际得<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这两个走的很强<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这算不算管不住手？<|im_end|>\\n<|im_start|>nameding：买的啥<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：宇邦<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@St*明明(投资是亏损的源头)\\u2005<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：鼎际得<|im_end|>\\n<|im_start|>nameding：又是次新股<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：对<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这种屡创新高的个股   我还是比较看好   咬一口就走了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@St*明明(投资是亏损的源头)\\u2005收盘能红  就收一个面钱就行了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：要求也不高   每天一个点   后面也挺不错<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：鼎际得   打51元  都没有成交量出来    真不知道后面会不会反水<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：卡倍亿   到了109元<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：MD   阶段新高了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：炒作 切到高送转概念了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这个票  北京抄家   他在元旦假期直播时候   说了这个票   红圈那个地方他资金没打进去   <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@所有人\\u2005首创证券  又一次攻17.35<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22：1<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：久其软件  获利了<|im_end|>\\n<|im_start|>nameding：妈的<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22：[惊讶]<|im_end|>\\n<|im_start|>nameding：@🌸st*雪（阳）\\u2005恢复了么<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22：差不多了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：真狗<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：只要一追就砸     低吸吧  吸的哆哆嗦嗦<|im_end|>\\n<|im_start|>nameding：@芝麻花儿\\u2005<|im_end|>\\n<|im_start|>nameding：这他妈的<|im_end|>\\n<|im_start|>nameding：打板就被核弹<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：我早盘买的票  也是那个熊样<|im_end|>\\n<|im_start|>nameding：我看也没什么套牢盘啊<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：获利盘多了   鼎际得就是这样的    <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：还有就是板块轮动太他妈快了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：你不打提前量     很容易核掉<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：不像博纳影业   我还能T  <|im_end|>\\n<|im_start|>nameding：我还坚守贵绳<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这跟线的最低价就是12.23元   这一段时间  它碰了好几次<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@St*明明(投资是亏损的源头)\\u2005贵绳股份  航母用钢索   还是可以的<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：你在意淫是不是习酒借壳<|im_end|>\\n<|im_start|>nameding：是的<|im_end|>\\n<|im_start|>nameding：哈哈哈<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：我在意淫   流浪地球2<|im_end|>\\n<|im_start|>nameding：你看美丽云走势<|im_end|>\\n<|im_start|>nameding：和易华是不是一样<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：影视传媒板块没整体上走强    不知道博纳是不是不涨的一根涨停<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22：大盘要回调，5天线太远，快减仓<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22：大盘先到5天线，撑不住到20线<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22：300也不行了，今天早上有开仓的吗<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22：众业达三连，动力源死股，特么的，选错害死人<|im_end|>\\n<|im_start|>nameding：大盘这么涨的飞起，连板的都没<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@A王牌康健\\u2005有  已经被干下去4个点了<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22：抗住啊<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22：明天看情况不对赶紧跑，大盘要回调<|im_end|>\\n<|im_start|>wxid_gbs3b881cj7f22：别人贪婪时要保持警惕<|im_end|>\\n<|im_start|>wxid_ew911lj4llo731：这个图形咋样<|im_end|>\\n<|im_start|>wxid_ew911lj4llo731：有意思吧<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：拉起来<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：[流泪]<|im_end|>\\n<|im_start|>nameding：早盘买的么<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：9点25分收货   收盘一个亏一个赚<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：5:5<|im_end|>\\n<|im_start|>nameding：挺好<|im_end|>\\n<|im_start|>nameding：我今天只买了一个 <|im_end|>\\n<|im_start|>nameding：高处不胜寒<|im_end|>\\n<|im_start|>nameding：还是贵绳好<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：券商很狗的<|im_end|>\\n<|im_start|>nameding：这个据说是房地产<|im_end|>\\n<|im_start|>nameding：我们好几个同事去那上班了<|im_end|>\\n<|im_start|>zzj457070921：尾盘进了医药<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：板块回到  上周二的板块上去了   <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：白酒与数字确权 信创<|im_end|>\\n<|im_start|>wxid_ew911lj4llo731：指数6连阳  连板跌成鬼<|im_end|>\\n', '')\n"
     ]
    }
   ],
   "source": [
    "def _format_msg(system_msg, user_msg, model_engine=\"Baichuan2-13b-chat\"):\n",
    "    if model_engine == \"Baichuan2-13b-chat\":\n",
    "        msg = \"<reserved_106>{}聊天记录均在```内。```{}```<reserved_107>\".format(system_msg, user_msg)\n",
    "    elif model_engine == \"Baichuan-13B-Chat\":\n",
    "        msg = \"<reserved_102>{}聊天记录均在```内。```{}```<reserved_103>\".format(system_msg, user_msg)\n",
    "    elif model_engine == \"chatglm2-6b\":\n",
    "        msg = \"[Round 1]\\n\\n问：{}聊天记录均在```内。```{}```\\n\\n答：\".format(system_msg, user_msg)\n",
    "    elif model_engine == \"Llama-2-13b-chat-hf\":\n",
    "        msg = \"<<SYS>>\\n{}\\n<</SYS>>\\n\\n[INST]{}[/INST]\".format(system_msg, user_msg)\n",
    "    else:\n",
    "        msg = \"{}聊天记录均在```内。```{}```\".format(system_msg, user_msg)\n",
    "    return msg\n",
    "\n",
    "system_msg = '''你是一个优秀的对话聊天助手。基于所有多轮聊天记录，你需要逐步完成如下任务，首先，将聊天记录的内容归纳出2-5个核心话题（话题名称要简洁），\\\n",
    "    并简洁的概括出每个人的观点或态度；最后针对每个话题给出总结和要点。提示：`<|im_start|>`代表每条聊天的开始，`<|im_end|>\\n`代表每条聊天的结束。'''\n",
    "user_msgs=[]\n",
    "chat_group_len=80\n",
    "chat_group_num=len(all_chats)//chat_group_len + 1\n",
    "for i in range(chat_group_num):\n",
    "    chat_group = all_chats[i*chat_group_len:(i+1)*chat_group_len]\n",
    "    # random.shuffle(chat_group)\n",
    "    user_msg=\"\".join([\"<|im_start|>{}<|im_end|>\\n\".format(chat) for chat in chat_group])\n",
    "    user_msgs.append((system_msg, user_msg, \"\"))  # (instruction, input, output)\n",
    "    # user_msgs.append((_format_msg(system_msg, user_msg), \"\", \"\"))  # (instruction, input, output)\n",
    "print(len(user_msgs), len(user_msgs[0][0]), user_msgs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def get_response_of_long_chat_summary(system_msg, user_msg, model_engine=\"baichuan2-13b-chat-chatsft-epo5\", max_tokens=1000, chunk_size=1500, chunk_overlap=200):\n",
    "    llm = CustomLLM(model_engine=model_engine, max_tokens=max_tokens)\n",
    "\n",
    "    # 初始化文本分割器\n",
    "    # splitter = RecursiveCharacterTextSplitter(separators=[\"<|im_end|>\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\"], chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "    def long_chat_summary(llm, chat_log):\n",
    "        # 使用文本分割器将聊天记录分割成多个块\n",
    "        docs = splitter.create_documents([chat_log])\n",
    "        print(len(docs[0].page_content), docs[0])\n",
    "\n",
    "        map_prompt = PromptTemplate(template=_format_msg(system_msg, \"{text}\"), input_variables=[\"text\"])\n",
    "        combine_prompt = PromptTemplate(template=\"{text}\", input_variables=[\"text\"])\n",
    "        chain = load_summarize_chain(llm=llm, chain_type='map_reduce', map_prompt=map_prompt, verbose=True)#, combine_prompt=combine_prompt) #\n",
    "        output = chain.run(docs)\n",
    "        return output\n",
    "\n",
    "    # 测试用例\n",
    "    # user_msg = ('这是一段非常长的聊天记录，需要被分割成多个块进行摘要.' * 5 + '<|im_end|>\\n') *5\n",
    "    summaries = long_chat_summary(llm, user_msg)\n",
    "    return summaries\n",
    "\n",
    "# get_response_of_long_chat_summary(system_msg,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473 page_content='<|im_start|>nameding：@🌸st*雪（阳）\\u2005<|im_end|>\\n<|im_start|>nameding：你51个红包多少钱<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22：没看啊，没几毛<|im_end|>\\n<|im_start|>nameding：8 帮我助力 f:/ 吧，上抖-yin一起冲吧！理唱也拉慢名究但対<|im_end|>\\n<|im_start|>nameding：点了十几个红包才一块<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：注意氢能源    制氢，储氢<|im_end|>\\n<|im_start|>zzj457070921：兰石重装我一直埋伏着<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：镇洋已经启动   乔源也涨了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：收获宇邦新材   鼎际得<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这两个走的很强<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这算不算管不住手？<|im_end|>\\n<|im_start|>nameding：买的啥<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：宇邦<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@St*明明(投资是亏损的源头)\\u2005<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：鼎际得<|im_end|>\\n<|im_start|>nameding：又是次新股<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：对<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这种屡创新高的个股   我还是比较看好   咬一口就走了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@St*明明(投资是亏损的源头)\\u2005收盘能红  就收一个面钱就行了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：要求也不高   每天一个点   后面也挺不错<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：鼎际得   打51元  都没有成交量出来    真不知道后面会不会反水<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：卡倍亿   到了109元<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：MD   阶段新高了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：炒作 切到高送转概念了<|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：这个票  北京抄家   他在元旦假期直播时候   说了这个票   红圈那个地方他资金没打进去   <|im_end|>\\n<|im_start|>wxid_2xgo1gspcjag22：@所有人\\u2005首创证券  又一次攻17.35<|im_end|>\\n<|im_start|>wxid_2k71jfnx1xbp22：1<|im_end|>' metadata={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4578 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1926 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3062 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2671 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2148 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# gpt-35-turbo\n",
      "===========================================\n",
      "\n",
      "\n",
      "# baichuan2-13b-chat-chatsft-epo5\n",
      "===========================================\n",
      "话题1：微信红包金额\n",
      "- nameding的观点：觉得花8块钱买51个红包很不划算。\n",
      "- wxid_2k71jfnx1xbp22的观点：对微信红包的金额不感兴趣，认为没有几毛钱。\n",
      "\n",
      "话题2：股票投资策略\n",
      "- wxid_2xgo1gspcjag22的观点：关注氢能源、制氢、储氢等概念股，认为镇洋和乔源走势强劲。\n",
      "- zzj457070921的观点：潜伏在兰石重装这只股票中，认为该股有望上涨。\n",
      "\n",
      "话题3：新股交易策略\n",
      "- wxid_2xgo1gspcjag22的观点：对新股鼎际得和宇邦新材持乐观态度，认为它们走势强劲。\n",
      "- nameding的观点：认同鼎际得的强势表现，但对宇邦新材持有怀疑态度。\n",
      "\n",
      "总结和要点：\n",
      "- 微信红包金额：nameding觉得花8块钱买51个红包很不划算，而wxid_2k71jfnx1xbp22对微信红包的金额不感兴趣。\n",
      "- 股票投资策略：wxid_2xgo1gspcjag22关注氢能源、制氢、储氢等概念股，认为镇洋和乔源走势强劲，而zzj457070921潜伏在兰石重装这只股票中。\n",
      "- 新股交易策略：wxid_2xgo1gspcjag22对新股鼎际得和宇邦新材持乐观态度，认为它们走势强劲，而nameding对宇邦新材持有怀疑态度。\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_engines=[\"baichuan2-13b-chat-chatsft-epo5\"]\n",
    "\n",
    "resps_model = []\n",
    "for inst,input,gpt_output in user_msgs[:1]:\n",
    "    resps=[inst,gpt_output]\n",
    "    for model in model_engines:\n",
    "        try:\n",
    "            # response = get_response_of_modelhub(inst, system_msg=input, model_engine=model, max_tokens=1000)\n",
    "            response = get_response_of_long_chat_summary(inst, input, model_engine=model, max_tokens=1000)\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"{e}\")\n",
    "            # time.sleep(3)\n",
    "            continue\n",
    "        # except Exception as e:\n",
    "        #     print(f\"捕获到异常：{e}\")\n",
    "        #     continue\n",
    "        resps.append(response)\n",
    "        print(\"\\n# {}\\n===========================================\".format(\"gpt-35-turbo\"))\n",
    "        print(gpt_output)\n",
    "        print(\"\\n# {}\\n===========================================\".format(model))\n",
    "        # print(response['generated_text'])\n",
    "        print(response)\n",
    "        print('\\n\\n')\n",
    "    resps_model.append(resps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
